{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we'll explore how we can use Deep Learning for sequence labelling tasks such as part-of-speech tagging or named entity recognition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our experiments we'll reuse the Dutch CoNLL-2002 data has four kinds of named entities (people, locations, organizations and miscellaneous entities) and comes split into a training, development and test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2002 to\n",
      "[nltk_data]     /Users/mrunalikhandat/nltk_data...\n",
      "[nltk_data]   Package conll2002 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('De', 'Art', 'O'),\n",
       "  ('tekst', 'N', 'O'),\n",
       "  ('van', 'Prep', 'O'),\n",
       "  ('het', 'Art', 'O'),\n",
       "  ('arrest', 'N', 'O'),\n",
       "  ('is', 'V', 'O'),\n",
       "  ('nog', 'Adv', 'O'),\n",
       "  ('niet', 'Adv', 'O'),\n",
       "  ('schriftelijk', 'Adj', 'O'),\n",
       "  ('beschikbaar', 'Adj', 'O'),\n",
       "  ('maar', 'Conj', 'O'),\n",
       "  ('het', 'Art', 'O'),\n",
       "  ('bericht', 'N', 'O'),\n",
       "  ('werd', 'V', 'O'),\n",
       "  ('alvast', 'Adv', 'O'),\n",
       "  ('bekendgemaakt', 'V', 'O'),\n",
       "  ('door', 'Prep', 'O'),\n",
       "  ('een', 'Art', 'O'),\n",
       "  ('communicatiebureau', 'N', 'O'),\n",
       "  ('dat', 'Conj', 'O'),\n",
       "  ('Floralux', 'N', 'B-ORG'),\n",
       "  ('inhuurde', 'V', 'O'),\n",
       "  ('.', 'Punc', 'O')],\n",
       " [('In', 'Prep', 'O'),\n",
       "  (\"'81\", 'Num', 'O'),\n",
       "  ('regulariseert', 'V', 'O'),\n",
       "  ('de', 'Art', 'O'),\n",
       "  ('toenmalige', 'Adj', 'O'),\n",
       "  ('Vlaamse', 'Adj', 'B-MISC'),\n",
       "  ('regering', 'N', 'O'),\n",
       "  ('de', 'Art', 'O'),\n",
       "  ('toestand', 'N', 'O'),\n",
       "  ('met', 'Prep', 'O'),\n",
       "  ('een', 'Art', 'O'),\n",
       "  ('BPA', 'N', 'B-MISC'),\n",
       "  ('dat', 'Pron', 'O'),\n",
       "  ('het', 'Art', 'O'),\n",
       "  ('bedrijf', 'N', 'O'),\n",
       "  ('op', 'Prep', 'O'),\n",
       "  ('eigen', 'Pron', 'O'),\n",
       "  ('kosten', 'N', 'O'),\n",
       "  ('heeft', 'V', 'O'),\n",
       "  ('laten', 'V', 'O'),\n",
       "  ('opstellen', 'V', 'O'),\n",
       "  ('.', 'Punc', 'O')],\n",
       " [('publicatie', 'N', 'O')]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data from conll2002 dataset\n",
    "import nltk\n",
    "nltk.download('conll2002')\n",
    "\n",
    "train_sents = list(nltk.corpus.conll2002.iob_sents('ned.train'))\n",
    "dev_sents = list(nltk.corpus.conll2002.iob_sents('ned.testa'))\n",
    "test_sents = list(nltk.corpus.conll2002.iob_sents('ned.testb'))\n",
    "\n",
    "train_sents[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could you explain A bidirectional LSTM (BiLSTM) (30%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional LSTM-\n",
    "\n",
    "Bidirectional LSTM stands for Bidirectional Long Short Term Memory structures. LSTMs are basically Recurrent Neural Networks. LSTMs are used to predict the next element after the current element. Forward LSTMs use the previous elements to predict the next element. Whereas Backward LSTMs use the next elements in the training dataset to predict the next element after the current element.\n",
    "  \n",
    "      Consider an example, I am Peter ____ is what he says\n",
    "\n",
    "Forward LSTMs will use 'I am' to predict the blank. Whereas, Backward LSTMs will use 'is what he says' to make a prediction of the blank space. Bi-LSTM combines outputs from both and gives a final output. Bi-LSTMs are useful in NLP as context of the sentence can be conveyed by both before and after parts of the blank.   \n",
    "Bi-LSTMs are used in both supervised and unsupervised learning algorithms. Bi-LSTMs are achieved by feeding the data in forward and backward manner. Bi-LSTMs are faster and achieve better results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': <torchtext.data.field.Field object at 0x1066ffbd0>, 'text': <torchtext.data.field.Field object at 0x1066ff910>}\n",
      "['De', 'tekst', 'van', 'het', 'arrest', 'is', 'nog', 'niet', 'schriftelijk', 'beschikbaar', 'maar', 'het', 'bericht', 'werd', 'alvast', 'bekendgemaakt', 'door', 'een', 'communicatiebureau', 'dat', 'Floralux', 'inhuurde', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O']\n",
      "Train: 15806\n",
      "Dev: 2895\n",
      "Test: 5195\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Example\n",
    "from torchtext.data import Field, Dataset\n",
    "\n",
    "text_field = Field(sequential=True, tokenize=lambda x:x, include_lengths=True) # Default behaviour is to tokenize by splitting\n",
    "label_field = Field(sequential=True, tokenize=lambda x:x, is_target=True)\n",
    "\n",
    "def read_data(sentences):\n",
    "    \"\"\"\n",
    "    Returns datasets with labels and tokens\n",
    "    \n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    fields = {'sentence_labels': ('labels', label_field),\n",
    "              'sentence_tokens': ('text', text_field)}\n",
    "    \n",
    "    for sentence in sentences: \n",
    "        tokens = [t[0] for t in sentence]\n",
    "        labels = [t[2] for t in sentence]\n",
    "        \n",
    "        e = Example.fromdict({\"sentence_labels\": labels, \"sentence_tokens\": tokens},\n",
    "                             fields=fields)\n",
    "        examples.append(e)\n",
    "    \n",
    "    return Dataset(examples, fields=[('labels', label_field), ('text', text_field)])\n",
    "\n",
    "train_data = read_data(train_sents)\n",
    "dev_data = read_data(dev_sents)\n",
    "test_data = read_data(test_sents)\n",
    "\n",
    "print(train_data.fields)\n",
    "print(train_data[0].text)\n",
    "print(train_data[0].labels)\n",
    "\n",
    "print(\"Train:\", len(train_data))\n",
    "print(\"Dev:\", len(dev_data))\n",
    "print(\"Test:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building vocab from training data\n",
    "VOCAB_SIZE = 20000\n",
    "\n",
    "text_field.build_vocab(train_data, max_size=VOCAB_SIZE)\n",
    "label_field.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import BucketIterator\n",
    "# Getting iterator using data; iterator is used for training, testing LSTMs\n",
    "BATCH_SIZE = 32\n",
    "train_iter = BucketIterator(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                            sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "dev_iter = BucketIterator(dataset=dev_data, batch_size=BATCH_SIZE, \n",
    "                          sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "test_iter = BucketIterator(dataset=test_data, batch_size=BATCH_SIZE, \n",
    "                           sort_key=lambda x: len(x.text), sort_within_batch=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained embeddings\n",
      "Initializing embedding matrix\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EMBEDDING_PATH = os.path.join(os.path.expanduser(\"~\"), \"Downloads/cc.nl.300.vec\")\n",
    "\n",
    "def load_embeddings(path):\n",
    "    \"\"\" \n",
    "    Load the FastText embeddings from the embedding file. \n",
    "    Output- Embeddings as a dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Loading pre-trained embeddings\")\n",
    "    \n",
    "    embeddings = {}\n",
    "    with open(EMBEDDING_PATH) as i:\n",
    "        for line in i:\n",
    "            if len(line) > 2: \n",
    "                line = line.strip().split()\n",
    "                word = line[0]\n",
    "                embedding = np.array(line[1:])\n",
    "                embeddings[word] = embedding\n",
    "    \n",
    "    return embeddings\n",
    "    \n",
    "\n",
    "def initialize_embeddings(embeddings, vocabulary):\n",
    "    \"\"\" \n",
    "    Use the pre-trained embeddings to initialize an embedding matrix.\n",
    "    Output- embedding matrix so that words in embeddings can be accessed\n",
    "            by their index. Index of a word in vocab and embedding matrix is same\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Initializing embedding matrix\")\n",
    "    embedding_size = len(embeddings[\".\"])\n",
    "    embedding_matrix = np.zeros((len(vocabulary), embedding_size), dtype=np.float32)\n",
    "                                \n",
    "    for idx, word in enumerate(vocabulary.itos): \n",
    "        if word in embeddings:\n",
    "            embedding_matrix[idx,:] = embeddings[word]\n",
    "            \n",
    "    return embedding_matrix\n",
    "\n",
    "embeddings = load_embeddings(EMBEDDING_PATH)\n",
    "embedding_matrix = initialize_embeddings(embeddings, text_field.vocab)\n",
    "embedding_matrix = torch.from_numpy(embedding_matrix).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model (70%)\n",
    "\n",
    "Next, we create our BiLSTM model. It consists of four layers:\n",
    "    \n",
    "- An embedding layer that maps one-hot word vectors to dense word embeddings. These embeddings are either pretrained or trained from scratch.\n",
    "- A bidirectional LSTM layer that reads the text both front to back and back to front. For each word, this LSTM produces two output vectors of dimensionality `hidden_dim`, which are concatenated to a vector of `2*hidden_dim`.\n",
    "- A dropout layer that helps us avoid overfitting by dropping a certain percentage of the items in the LSTM output.\n",
    "- A dense layer that projects the LSTM output to an output vector with a dimensionality equal to the number of labels.\n",
    "\n",
    "Could you try to apply your desgined BiLSTM model to do NER labeling?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, output_size, embeddings=None):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        \n",
    "        # Embedding Layer- used pretrained word embeddings\n",
    "        if embeddings is None:\n",
    "            self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        else:\n",
    "            self.embeddings = nn.Embedding.from_pretrained(embeddings)\n",
    "        \n",
    "        # LSTM Layer- Use bidirectional= True for BiLSTM\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, num_layers=1)\n",
    "        \n",
    "        # dropout layer- To avoid overfitting\n",
    "        self.dropout_layer = nn.Dropout(p=0.25)\n",
    "\n",
    "        # Dense Layer- A fully connected layer to get tags\n",
    "        self.hidden2tag = nn.Linear(2*hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, batch_text, batch_lengths):\n",
    "\n",
    "        embeddings = self.embeddings(batch_text)\n",
    "        \n",
    "        packed_seqs = pack_padded_sequence(embeddings, batch_lengths)\n",
    "        lstm_output, _ = self.lstm(packed_seqs)\n",
    "        lstm_output, _ = pad_packed_sequence(lstm_output)\n",
    "        lstm_output = self.dropout_layer(lstm_output)\n",
    "        \n",
    "        logits = self.hidden2tag(lstm_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "\n",
    "def remove_predictions_for_masked_items(predicted_labels, correct_labels): \n",
    "\n",
    "    predicted_labels_without_mask = []\n",
    "    correct_labels_without_mask = []\n",
    "        \n",
    "    for p, c in zip(predicted_labels, correct_labels):\n",
    "        if c > 1:\n",
    "            predicted_labels_without_mask.append(p)\n",
    "            correct_labels_without_mask.append(c)\n",
    "            \n",
    "    return predicted_labels_without_mask, correct_labels_without_mask\n",
    "\n",
    "\n",
    "def train(model, train_iter, dev_iter, batch_size, max_epochs, num_batches, patience, output_path):\n",
    "    \"\"\"\n",
    "    Training model\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=1)  # we mask the <pad> labels\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    train_f_score_history = []\n",
    "    dev_f_score_history = []\n",
    "    no_improvement = 0\n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        total_loss = 0\n",
    "        predictions, correct = [], []\n",
    "        for batch in tqdm(train_iter, total=num_batches, desc=f\"Epoch {epoch}\"):\n",
    "            # Clear initial weights\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            text_length, cur_batch_size = batch.text[0].shape\n",
    "            \n",
    "            pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size*text_length, NUM_CLASSES)\n",
    "            gold = batch.labels.to(device).view(cur_batch_size*text_length)\n",
    "            \n",
    "            loss = criterion(pred, gold)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "\n",
    "            _, pred_indices = torch.max(pred, 1)\n",
    "            \n",
    "            predicted_labels = list(pred_indices.cpu().numpy())\n",
    "            correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "            \n",
    "            predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, \n",
    "                                                                                   correct_labels)\n",
    "            \n",
    "            predictions += predicted_labels\n",
    "            correct += correct_labels\n",
    "\n",
    "        train_scores = precision_recall_fscore_support(correct, predictions, average=\"micro\")\n",
    "        train_f_score_history.append(train_scores[2])\n",
    "            \n",
    "        print(\"Total training loss:\", total_loss)\n",
    "        print(\"Training performance:\", train_scores)\n",
    "        \n",
    "        total_loss = 0\n",
    "        predictions, correct = [], []\n",
    "        for batch in dev_iter:\n",
    "\n",
    "            text_length, cur_batch_size = batch.text[0].shape\n",
    "\n",
    "            pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size * text_length, NUM_CLASSES)\n",
    "            gold = batch.labels.to(device).view(cur_batch_size * text_length)\n",
    "            loss = criterion(pred, gold)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, pred_indices = torch.max(pred, 1)\n",
    "            predicted_labels = list(pred_indices.cpu().numpy())\n",
    "            correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "            \n",
    "            predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, \n",
    "                                                                                   correct_labels)\n",
    "            \n",
    "            predictions += predicted_labels\n",
    "            correct += correct_labels\n",
    "\n",
    "        dev_scores = precision_recall_fscore_support(correct, predictions, average=\"micro\")\n",
    "            \n",
    "        print(\"Total development loss:\", total_loss)\n",
    "        print(\"Development performance:\", dev_scores)\n",
    "        \n",
    "        dev_f = dev_scores[2]\n",
    "        # If development F-score does not improve in consecutive patience value, then stop training\n",
    "        if len(dev_f_score_history) > patience and dev_f < max(dev_f_score_history):\n",
    "            no_improvement += 1\n",
    "\n",
    "        elif len(dev_f_score_history) == 0 or dev_f > max(dev_f_score_history):\n",
    "            print(\"Saving model as Development F-score improved.\")\n",
    "            torch.save(model, output_path)\n",
    "            no_improvement = 0\n",
    "            \n",
    "        if no_improvement > patience:\n",
    "            print(\"Development F-score did not improve for last \",no_improvement,\" epochs. Stop training!\")\n",
    "            dev_f_score_history.append(dev_f)\n",
    "            break\n",
    "            \n",
    "        dev_f_score_history.append(dev_f)\n",
    "        \n",
    "    return train_f_score_history, dev_f_score_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_iter, batch_size, labels, target_names): \n",
    "    \"\"\"\n",
    "    Test model\n",
    "    \n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    predictions, correct = [], []\n",
    "    for batch in test_iter:\n",
    "\n",
    "        text_length, cur_batch_size = batch.text[0].shape\n",
    "\n",
    "        pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size * text_length, NUM_CLASSES)\n",
    "        gold = batch.labels.to(device).view(cur_batch_size * text_length)\n",
    "\n",
    "        _, pred_indices = torch.max(pred, 1)\n",
    "        predicted_labels = list(pred_indices.cpu().numpy())\n",
    "        correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "\n",
    "        predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, \n",
    "                                                                               correct_labels)\n",
    "\n",
    "        predictions += predicted_labels\n",
    "        correct += correct_labels\n",
    "    \n",
    "    print(classification_report(correct, predictions, labels=labels, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mrunalikhandat/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ab756e22c04d94b2253f59315c62a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 0', max=494.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training loss: 213.36526759713888\n",
      "Training performance: (0.9285249008112749, 0.9285249008112749, 0.9285249008112749, None)\n",
      "Total development loss: 24.779741942882538\n",
      "Development performance: (0.929790113301669, 0.929790113301669, 0.929790113301669, None)\n",
      "Saving model as Development F-score improved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mrunalikhandat/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type BiLSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffcc2b3191e4bac9ca1e7ecbf170635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=494.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training loss: 66.26967169297859\n",
      "Training performance: (0.9620319377825152, 0.9620319377825152, 0.9620319377825152, None)\n",
      "Total development loss: 17.876843596808612\n",
      "Development performance: (0.9411998832488656, 0.9411998832488656, 0.9411998832488656, None)\n",
      "Saving model as Development F-score improved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8e328df7fe4929bb0f4c7ef5abd949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 2', max=494.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training loss: 46.88644802197814\n",
      "Training performance: (0.9705592072797615, 0.9705592072797615, 0.9705592072797615, None)\n",
      "Total development loss: 18.160010691266507\n",
      "Development performance: (0.9409876084591504, 0.9409876084591504, 0.9409876084591504, None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379e796f2176463d8c2471db426e451f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 3', max=494.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training loss: 38.095161547418684\n",
      "Training performance: (0.9748820591776712, 0.9748820591776712, 0.9748820591776712, None)\n",
      "Total development loss: 16.179212007438764\n",
      "Development performance: (0.9452331042534561, 0.9452331042534561, 0.9452331042534561, None)\n",
      "Saving model as Development F-score improved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600045c841fd44539f3973fa0ec34017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 4', max=494.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training loss: 32.10703522944823\n",
      "Training performance: (0.9777146128185389, 0.9777146128185389, 0.9777146128185389, None)\n",
      "Total development loss: 18.099692140356638\n",
      "Development performance: (0.9446228142330246, 0.9446228142330246, 0.9446228142330246, None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a68aee15ac94ead862a9e7186c42d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 5', max=494.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training loss: 27.631763985438738\n",
      "Training performance: (0.980256015475415, 0.980256015475415, 0.980256015475415, None)\n",
      "Total development loss: 17.75517588527873\n",
      "Development performance: (0.9447024172791679, 0.9447024172791679, 0.9447024172791679, None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb933c95a9bb4f888df9588ff9a6edf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 6', max=494.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training loss: 24.32579001504928\n",
      "Training performance: (0.9820177256666864, 0.9820177256666864, 0.9820177256666864, None)\n",
      "Total development loss: 14.740148649085313\n",
      "Development performance: (0.9490009817709024, 0.9490009817709024, 0.9490009817709024, None)\n",
      "Saving model as Development F-score improved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1feb9f5790ff46d6b41c27c5a73808c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 7', max=494.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training loss: 21.339181425908464\n",
      "Training performance: (0.9837942401452794, 0.9837942401452794, 0.9837942401452794, None)\n",
      "Total development loss: 16.808311138360295\n",
      "Development performance: (0.947621195637753, 0.947621195637753, 0.947621195637753, None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19cb953f2a2942be9b863c9ff399042b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 8', max=494.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training loss: 18.903283227438806\n",
      "Training performance: (0.985245060302797, 0.985245060302797, 0.985245060302797, None)\n",
      "Total development loss: 16.67431971116457\n",
      "Development performance: (0.9482845543556133, 0.9482845543556133, 0.9482845543556133, None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3b012082f34b6689e8cf73e6e14a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 9', max=494.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training loss: 17.076296232728055\n",
      "Training performance: (0.9864195337636447, 0.9864195337636447, 0.9864195337636447, None)\n",
      "Total development loss: 15.731329553993419\n",
      "Development performance: (0.9502480961604798, 0.9502480961604798, 0.9502480961604798, None)\n",
      "Saving model as Development F-score improved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464a1f60a6e94ba88fb47a57d2d3d722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 10', max=494.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training loss: 15.140395860085846\n",
      "Training performance: (0.9876038767493733, 0.9876038767493733, 0.9876038767493733, None)\n",
      "Total development loss: 17.4563724522377\n",
      "Development performance: (0.9492663252580466, 0.9492663252580466, 0.9492663252580466, None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039f620320ac4048b9947585a0c7fef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 11', max=494.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training loss: 13.481919855301385\n",
      "Training performance: (0.9888128935473046, 0.9888128935473046, 0.9888128935473046, None)\n",
      "Total development loss: 16.9878794598917\n",
      "Development performance: (0.9495316687451907, 0.9495316687451907, 0.9495316687451907, None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5608a97feab349fcbb705f13f5d588b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 12', max=494.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training loss: 11.67038989529101\n",
      "Training performance: (0.9903229308541087, 0.9903229308541087, 0.9903229308541087, None)\n",
      "Total development loss: 18.92997093341546\n",
      "Development performance: (0.9495051343964762, 0.9495051343964762, 0.9495051343964762, None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2347381f95a34a368d93de68c59eaecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 13', max=494.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training loss: 10.38216796163033\n",
      "Training performance: (0.9912259923807268, 0.9912259923807268, 0.9912259923807268, None)\n",
      "Total development loss: 18.53918498835992\n",
      "Development performance: (0.9488683100273304, 0.9488683100273304, 0.9488683100273304, None)\n",
      "Development F-score did not improve for last  4  epochs. Stop training!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = len(label_field.vocab)\n",
    "MAX_EPOCHS = 50\n",
    "PATIENCE = 3\n",
    "OUTPUT_PATH = \"/tmp/bilstm\"\n",
    "num_batches = math.ceil(len(train_data) / BATCH_SIZE)\n",
    "\n",
    "tagger = BiLSTM(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE+2, NUM_CLASSES, embeddings=embedding_matrix)  \n",
    "\n",
    "train_f, dev_f = train(tagger.to(device), train_iter, dev_iter, BATCH_SIZE, MAX_EPOCHS, \n",
    "                       num_batches, PATIENCE, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "# Plot performance of the model through epochs\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "df = pd.DataFrame({'epochs': range(0,len(train_f)), \n",
    "                  'train_f': train_f, \n",
    "                   'dev_f': dev_f})\n",
    " \n",
    "# multiple line plot\n",
    "plt.plot('epochs', 'train_f', data=df, color='violet', linewidth=5)\n",
    "plt.plot('epochs', 'dev_f', data=df, color='orange', linewidth=5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM(\n",
       "  (embeddings): Embedding(20002, 300)\n",
       "  (lstm): LSTM(300, 256, bidirectional=True)\n",
       "  (dropout_layer): Dropout(p=0.25, inplace=False)\n",
       "  (hidden2tag): Linear(in_features=512, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = torch.load(OUTPUT_PATH)\n",
    "tagger.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "\t\t\tPerformance Evaluation\n",
      "************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.86      0.66      0.75       774\n",
      "       I-LOC       0.48      0.51      0.50        49\n",
      "      B-MISC       0.85      0.48      0.61      1187\n",
      "      I-MISC       0.70      0.27      0.39       410\n",
      "       B-ORG       0.83      0.51      0.63       882\n",
      "       I-ORG       0.86      0.49      0.63       551\n",
      "       B-PER       0.87      0.65      0.74      1098\n",
      "       I-PER       0.95      0.71      0.81       807\n",
      "\n",
      "   micro avg       0.86      0.56      0.68      5758\n",
      "   macro avg       0.80      0.53      0.63      5758\n",
      "weighted avg       0.85      0.56      0.67      5758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Performance evaluation report of the BiLSTM model\n",
    "labels = label_field.vocab.itos[3:]\n",
    "labels = sorted(labels, key=lambda x: x.split(\"-\")[-1])\n",
    "label_idxs = [label_field.vocab.stoi[l] for l in labels]\n",
    "print(\"*\"*60)\n",
    "print(\"\\t\\t\\tPerformance Evaluation\")\n",
    "print(\"*\"*60)\n",
    "\n",
    "test(tagger, test_iter, BATCH_SIZE, labels = label_idxs, target_names = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References-\n",
    "  \n",
    "- https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "- https://datascience.stackexchange.com/questions/25650/what-is-lstm-bilstm-and-when-to-use-them\n",
    "- https://medium.com/@raghavaggarwal0089/bi-lstm-bc3d68da8bd0\n",
    "- https://github.com/nlptown/nlp-notebooks/blob/master/Sequence%20Labelling%20with%20a%20BiLSTM%20in%20PyTorch.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
