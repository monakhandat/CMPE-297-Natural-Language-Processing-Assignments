{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating spaCy's Named Entity Recognition System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A toy example (40%)\n",
    "\n",
    "spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. In this HW, we will try to utilize spaCy to do NER. Given a sentence: 'Theresa May is a British politician serving as Prime Minister of the United Kingdom and Leader of the Conservative Party since 2016', could you try to apply spaCy to label what words are geo-political entity (GPE), the organization (ORG), date, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Theresa     </td><td>B</td><td>PERSON</td></tr>\n",
       "<tr><td>May         </td><td>I</td><td>PERSON</td></tr>\n",
       "<tr><td>is          </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>a           </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>British     </td><td>B</td><td>NORP  </td></tr>\n",
       "<tr><td>politician  </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>serving     </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>as          </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>Prime       </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>Minister    </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>of          </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>the         </td><td>B</td><td>GPE   </td></tr>\n",
       "<tr><td>United      </td><td>I</td><td>GPE   </td></tr>\n",
       "<tr><td>Kingdom     </td><td>I</td><td>GPE   </td></tr>\n",
       "<tr><td>and         </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>Leader      </td><td>B</td><td>ORG   </td></tr>\n",
       "<tr><td>of          </td><td>I</td><td>ORG   </td></tr>\n",
       "<tr><td>the         </td><td>I</td><td>ORG   </td></tr>\n",
       "<tr><td>Conservative</td><td>I</td><td>ORG   </td></tr>\n",
       "<tr><td>Party       </td><td>I</td><td>ORG   </td></tr>\n",
       "<tr><td>since       </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>2016        </td><td>B</td><td>DATE  </td></tr>\n",
       "<tr><td>.           </td><td>O</td><td>      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "import spacy\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "text = \"Theresa May is a British politician serving as Prime Minister of the United Kingdom and Leader of the Conservative Party since 2016. \"\n",
    "\n",
    "doc = nlp(text)\n",
    "entities = [(t.text, t.ent_iob_, t.ent_type_) for t in doc]\n",
    "display(HTML(tabulate.tabulate(entities, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your NER labels should not be good, you can try utilize some training texts to improve your NER labeling, try following training texts and redo this problem? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_texts = [\n",
    "    ([\"Theresa\", \"May\", \"is\", \"determined\", \"to\", \"leave\", \"the\", \"EU\", \"in\", \"March\", \".\"],\n",
    "     [\"B-PERSON\", \"L-PERSON\", \"O\", \"O\", \"O\", \"O\", \"O\", \"U-ORG\", \"O\", \"U-DATE\", \"O\"]\n",
    "    ),\n",
    "    ([\"Theresa\", \"May\", \"says\", \"she\", \"will\", \"seek\", \"a\", \"pragmatic\", \"Brexit\", \"deal\", \".\"],\n",
    "     [\"B-PERSON\", \"L-PERSON\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]\n",
    "    ),\n",
    "    ([\"Theresa\", \"May\", \"vows\", \"to\", \"battle\", \"in\", \"Brussels\", \".\"],\n",
    "     [\"B-PERSON\", \"L-PERSON\", \"O\", \"O\", \"O\", \"O\", \"U-GPE\", \"O\"]\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "from spacy.gold import GoldParse\n",
    "\n",
    "training_data = []\n",
    "for tokens, annotation in training_texts:\n",
    "    doc = Doc(nlp.vocab, words=tokens)\n",
    "    gold = GoldParse(doc, entities=annotation)\n",
    "    training_data.append((doc, gold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mrunalikhandat/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8420b21a843d4fb9ac35b2d09b31f496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# Random shuffling of data\n",
    "for _ in tqdm(range(10)):\n",
    "    random.shuffle(training_data)\n",
    "    for doc, gold in training_data:\n",
    "        nlp.update([doc], [gold], drop=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Theresa     </td><td>B</td><td>PERSON</td></tr>\n",
       "<tr><td>May         </td><td>I</td><td>PERSON</td></tr>\n",
       "<tr><td>is          </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>a           </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>British     </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>politician  </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>serving     </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>as          </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>Prime       </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>Minister    </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>of          </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>the         </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>United      </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>Kingdom     </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>and         </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>Leader      </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>of          </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>the         </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>Conservative</td><td>O</td><td>      </td></tr>\n",
       "<tr><td>Party       </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>since       </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>2016        </td><td>B</td><td>DATE  </td></tr>\n",
       "<tr><td>.           </td><td>O</td><td>      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"Theresa May is a British politician serving as Prime Minister of the United Kingdom and Leader of the Conservative Party since 2016. \"\n",
    "\n",
    "doc = nlp(text) # Converting string text to nlp object\n",
    "entities = [(t.text, t.ent_iob_, t.ent_type_) for t in doc]\n",
    "display(HTML(tabulate.tabulate(entities, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install wget on terminal, if you don't have it. If using wget in notebook is problematic, then perform following commands using Terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-27 20:06:11--  https://raw.githubusercontent.com/teropa/nlp/master/resources/corpora/conll2002/ned.train\n",
      "Resolving raw.githubusercontent.com... 151.101.40.133\n",
      "Connecting to raw.githubusercontent.com|151.101.40.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2377174 (2.3M) [text/plain]\n",
      "Saving to: '/Users/mrunalikhandat/Downloads/data/ner/ned.train.2'\n",
      "\n",
      "ned.train.2         100%[===================>]   2.27M  2.78MB/s    in 0.8s    \n",
      "\n",
      "2020-04-27 20:06:12 (2.78 MB/s) - '/Users/mrunalikhandat/Downloads/data/ner/ned.train.2' saved [2377174/2377174]\n",
      "\n",
      "--2020-04-27 20:06:12--  https://raw.githubusercontent.com/teropa/nlp/master/resources/corpora/conll2002/ned.testa\n",
      "Resolving raw.githubusercontent.com... 151.101.40.133\n",
      "Connecting to raw.githubusercontent.com|151.101.40.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 450785 (440K) [text/plain]\n",
      "Saving to: '/Users/mrunalikhandat/Downloads/data/ner/ned.testa.2'\n",
      "\n",
      "ned.testa.2         100%[===================>] 440.22K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2020-04-27 20:06:13 (3.04 MB/s) - '/Users/mrunalikhandat/Downloads/data/ner/ned.testa.2' saved [450785/450785]\n",
      "\n",
      "--2020-04-27 20:06:13--  https://raw.githubusercontent.com/teropa/nlp/master/resources/corpora/conll2002/ned.testb\n",
      "Resolving raw.githubusercontent.com... 151.101.40.133\n",
      "Connecting to raw.githubusercontent.com|151.101.40.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 814282 (795K) [text/plain]\n",
      "Saving to: '/Users/mrunalikhandat/Downloads/data/ner/ned.testb.2'\n",
      "\n",
      "ned.testb.2         100%[===================>] 795.20K  2.22MB/s    in 0.4s    \n",
      "\n",
      "2020-04-27 20:06:14 (2.22 MB/s) - '/Users/mrunalikhandat/Downloads/data/ner/ned.testb.2' saved [814282/814282]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/teropa/nlp/master/resources/corpora/conll2002/ned.train -P ~/Downloads/data/ner/\n",
    "!wget https://raw.githubusercontent.com/teropa/nlp/master/resources/corpora/conll2002/ned.testa -P ~/Downloads/data/ner/\n",
    "!wget https://raw.githubusercontent.com/teropa/nlp/master/resources/corpora/conll2002/ned.testb -P ~/Downloads/data/ner/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an NER model on Dutch CONLL data (60%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, however, you'll likely have more training data than just three examples with the same entity. Things become really interesting when you have access to a labelled data set of hundreds or more examples of several entity types: CVs that have been labelled with job titles and skills, medical documents that have been labelled with symptoms and diseases, etc.\n",
    "\n",
    "As an example, let's train a Named Entity Recognition model on the Dutch data that was collected for the [CoNLL-2002 Shared Task](https://www.clips.uantwerpen.be/conll2002/ner/). This data can be downloaded from Github. Can you evalute spaCy model performance, e.g., get precision, recall, f1-score for each label LOC, MISC, O, ORG, PER, etc.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "train_file = \"data/ner/ned.train\"\n",
    "dev_file = \"data/ner/ned.testa\"\n",
    "test_file = \"data/ner/ned.testb\"\n",
    "\n",
    "def read_conll_file(f):\n",
    "    \"\"\"\n",
    "    Used to read file data and store\n",
    "    it as a list. \n",
    "    Output- list\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(f) as i:\n",
    "        sentences = i.read().strip().split(\"\\n\\n\")\n",
    "        \n",
    "    for sentence in sentences:\n",
    "        data.append([token.split() for token in sentence.split(\"\\n\")])\n",
    "\n",
    "    return data\n",
    "        \n",
    "train_data = read_conll_file(train_file)\n",
    "dev_data = read_conll_file(dev_file)\n",
    "test_data = read_conll_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "def evaluate(model, data, verbose=0): \n",
    "    \"\"\"\n",
    "    Function to evaluate\n",
    "    performance of the trained nlp model\n",
    "    Output- A list of attributes with precision, recall, F1 score, support\n",
    "            of each attribute in the document\n",
    "    \n",
    "    \"\"\"\n",
    "    ner = model.get_pipe(\"ner\")\n",
    "    \n",
    "    correct, predicted = [], []\n",
    "    for sentence in data:\n",
    "        tokens = [t[0] for t in sentence]\n",
    "        ent_labels = [t[2].split(\"-\")[-1] for t in sentence]\n",
    "        \n",
    "        doc = Doc(model.vocab, words=tokens)\n",
    "        ner(doc)\n",
    "        \n",
    "        pred_labels = [t.ent_type_ or \"O\" for t in doc]\n",
    "        correct += ent_labels\n",
    "        predicted += pred_labels\n",
    "        \n",
    "    if verbose:\n",
    "        print(classification_report(correct, predicted))\n",
    "    \n",
    "    return precision_recall_fscore_support(correct, predicted, average=\"micro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mrunalikhandat/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mrunalikhandat/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL       0.00      0.00      0.00         0\n",
      "        DATE       0.00      0.00      0.00         0\n",
      "       EVENT       0.00      0.00      0.00         0\n",
      "         FAC       0.00      0.00      0.00         0\n",
      "         GPE       0.00      0.00      0.00         0\n",
      "    LANGUAGE       0.00      0.00      0.00         0\n",
      "         LAW       0.00      0.00      0.00         0\n",
      "         LOC       0.22      0.02      0.04       823\n",
      "        MISC       0.00      0.00      0.00      1597\n",
      "       MONEY       0.00      0.00      0.00         0\n",
      "        NORP       0.00      0.00      0.00         0\n",
      "           O       0.98      0.91      0.94     63236\n",
      "     ORDINAL       0.00      0.00      0.00         0\n",
      "         ORG       0.48      0.31      0.37      1433\n",
      "         PER       0.00      0.00      0.00      1905\n",
      "     PERCENT       0.00      0.00      0.00         0\n",
      "      PERSON       0.00      0.00      0.00         0\n",
      "     PRODUCT       0.00      0.00      0.00         0\n",
      "    QUANTITY       0.00      0.00      0.00         0\n",
      "        TIME       0.00      0.00      0.00         0\n",
      " WORK_OF_ART       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.84     68994\n",
      "   macro avg       0.08      0.06      0.06     68994\n",
      "weighted avg       0.91      0.84      0.87     68994\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8447256283155057, 0.8447256283155057, 0.8447256283155057, None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing performance of the pretrained model- nl on our data\n",
    "import nl_core_news_sm\n",
    "nlp = nl_core_news_sm.load()\n",
    "evaluate(nlp, test_data, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy's NER has various types of entity recognition schemes for better annotation/labelling of the text. More information can be found at https://spacy.io/api/annotation. The conversion from IOB to BILUO is done here as BILUO is more efficient than IOB in recognizing tokens and gives better performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.gold import iob_to_biluo\n",
    "# Converting training_data from IOB annotation scheme to BILUO scheme\n",
    "training_data = []\n",
    "for sentence in train_data:\n",
    "    tokens = [t[0] for t in sentence]\n",
    "    ent_labels = iob_to_biluo([t[2] for t in sentence])\n",
    "    doc = Doc(nlp.vocab, words=tokens)\n",
    "    gold = GoldParse(doc, entities=ent_labels)\n",
    "    training_data.append((doc, gold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is the custom training of our data to create a better NER model. The steps followed in training the model are as follows:\n",
    "- Check for pretrained models. \n",
    "- If no model is assigned, create a pipe- 'ner'. If a model is given, check for the pipes in the model. If 'ner' is not present in the model pipes, add it. \n",
    "- For a given model, other pipes need to be disabled as training needs to be performed only on 'ner' model.\n",
    "- 'ner' pipe needs to be present in the model irrespective of new or training an existing model\n",
    "- Used a flag called reset_weights to ensure that 'ner' is present before starting the training\n",
    "- \"PER\", \"LOC\", \"ORG\", \"MISC\" labels need to be present in 'ner' pipe, they're added to 'ner'.\n",
    "- 'ner' pipe is trained using training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.util import minibatch\n",
    "from pathlib import Path\n",
    "\n",
    "def train(train_docs, dev_data, output_dir, model=None, max_epochs=100): \n",
    "    \"\"\"\n",
    "    Training a new model on given data\n",
    "    \"\"\"\n",
    "    reset_weights = False\n",
    "    print(nlp.pipe_names)\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "        reset_weights = True\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "    print(ner,reset_weights)\n",
    "    \n",
    "    if not model or reset_weights: \n",
    "        print(\"inside reset weights\")\n",
    "        model = spacy.blank(\"nl\")\n",
    "        ner = model.create_pipe(\"ner\")\n",
    "        model.add_pipe(ner, last=True)\n",
    "    for label in [\"PER\", \"LOC\", \"ORG\", \"MISC\"]: \n",
    "        ner.add_label(label)\n",
    "    model.begin_training()\n",
    "        \n",
    "    other_pipes = [pipe for pipe in model.pipe_names if pipe != 'ner']\n",
    "    print(other_pipes)\n",
    "    fscore_history = []\n",
    "    patience=3\n",
    "        \n",
    "    with model.disable_pipes(*other_pipes):\n",
    "        print(\"inside disable pipes\")\n",
    "    \n",
    "        for i in range(max_epochs):\n",
    "\n",
    "            losses = {}\n",
    "            random.shuffle(train_docs)\n",
    "            batches = minibatch(train_docs, size=32)\n",
    "            for batch in tqdm(batches):\n",
    "                docs, golds = zip(*batch)\n",
    "\n",
    "                model.update(\n",
    "                    docs,\n",
    "                    golds,\n",
    "                    drop=0.4,\n",
    "                    losses=losses)\n",
    "            print(\"Training Loss:\", losses)\n",
    "            \n",
    "            _, _, dev_f, _ = evaluate(model, dev_data)\n",
    "            print(\"Development F-score:\", dev_f)\n",
    "            \n",
    "            if len(fscore_history) > 0 and dev_f > max(fscore_history): \n",
    "                if output_dir is not None:\n",
    "                    output_dir = Path(output_dir)\n",
    "                    if not output_dir.exists():\n",
    "                        output_dir.mkdir()\n",
    "                    model.to_disk(output_dir)\n",
    "                    print(\"Saved model to\", output_dir)\n",
    "            \n",
    "            fscore_history.append(dev_f)\n",
    "            \n",
    "            if max(fscore_history) > max(fscore_history[-patience:]):\n",
    "                print(\"No improvement on development set. Stop training.\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner']\n",
      "<spacy.pipeline.pipes.EntityRecognizer object at 0x1a2dd604b0> False\n",
      "inside reset weights\n",
      "[]\n",
      "inside disable pipes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mrunalikhandat/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:38: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c22814c25c44f508b3f373672ec49e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 16851.210388486797}\n",
      "Development F-score: 0.9462408304864808\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b82cbec37f8459c8efca1571b16dfbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 10228.721772782765}\n",
      "Development F-score: 0.9592701464473928\n",
      "Saved model to models/spacy_ner_scratch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed333a2707642548a488d10857b549d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 8000.932297884683}\n",
      "Development F-score: 0.964248828156034\n",
      "Saved model to models/spacy_ner_scratch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375aa6bdedae4fb48308ee0eac941025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 6777.075392361529}\n",
      "Development F-score: 0.9648049574958291\n",
      "Saved model to models/spacy_ner_scratch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a9015ea45b48b99501cdd89bcb852d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 5890.74409409282}\n",
      "Development F-score: 0.9682741452821695\n",
      "Saved model to models/spacy_ner_scratch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ee2858765a42b097dd992a8feda094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 5191.929908104242}\n",
      "Development F-score: 0.9686448981753661\n",
      "Saved model to models/spacy_ner_scratch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d43d3d452384a49bb225165c0371925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 4795.659536664179}\n",
      "Development F-score: 0.9664468631657\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d785c80a6e4846159833d83e31ae2854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 4379.598490996272}\n",
      "Development F-score: 0.9688832393209925\n",
      "Saved model to models/spacy_ner_scratch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f41cb1e65b8402fb805c0cefdac436a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 4015.421437057075}\n",
      "Development F-score: 0.9677444982918885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb5540da01f45c190c581df66755f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 3791.0608238737577}\n",
      "Development F-score: 0.9686713805248802\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3935888cfc06410ca518d47ee6035c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 3425.342025940746}\n",
      "Development F-score: 0.9708958978840603\n",
      "Saved model to models/spacy_ner_scratch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54671fe84cdf42528cca27f3dec5e6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 3285.1435861859245}\n",
      "Development F-score: 0.9666322396122984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d942b08845ef40888f669a505ccb77be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 3077.7436384366774}\n",
      "Development F-score: 0.969121580466619\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420b08e330ff4949808285bd1d428426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 2809.3543861899543}\n",
      "Development F-score: 0.970207356796695\n",
      "No improvement on development set. Stop training.\n"
     ]
    }
   ],
   "source": [
    "# Training a model from scratch\n",
    "\n",
    "output_dir_scratch = \"models/spacy_ner_scratch\"\n",
    "train(training_data, dev_data, model=None, output_dir=output_dir_scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner']\n",
      "<spacy.pipeline.pipes.EntityRecognizer object at 0x1a2dd604b0> False\n",
      "['tagger', 'parser']\n",
      "inside disable pipes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mrunalikhandat/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:38: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c3f12a268a42ecb4d914585ffd29de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 114947.73417854309}\n",
      "Development F-score: 0.9525965943698524\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd6ce792283431f8aca55d75cd3d539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 110180.59282875061}\n",
      "Development F-score: 0.9591377346998226\n",
      "Saved model to models/spacy_ner_cntd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab57a3df2724a4f9e2706ab32190b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 108978.9408569336}\n",
      "Development F-score: 0.9605412992240672\n",
      "Saved model to models/spacy_ner_cntd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694fcabec11744fd8a6f607b41dd395c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 108514.84890174866}\n",
      "Development F-score: 0.9628717459813034\n",
      "Saved model to models/spacy_ner_cntd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ddee0238684d1c8d6ff0417602dfbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 108059.70310401917}\n",
      "Development F-score: 0.9624745107385927\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc982d0cda844b83976d57a57780637d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 107620.2323884964}\n",
      "Development F-score: 0.9600381345833002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7808f1c80c5e4e3a9684067055d81593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 107349.48663520813}\n",
      "Development F-score: 0.9650962633404836\n",
      "Saved model to models/spacy_ner_cntd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ff1b0934be45599c7bf46b187fd098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 106713.5507364273}\n",
      "Development F-score: 0.963189534175472\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8820e6fc504693b12c671d890d107b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 106931.87976264954}\n",
      "Development F-score: 0.9655199809327083\n",
      "Saved model to models/spacy_ner_cntd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae40b8e6d7c493aad3c6f3eaf5977de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 106780.37586402893}\n",
      "Development F-score: 0.9654934985831943\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8e429398d84c5d81e0869ef43aadb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 106683.66618347168}\n",
      "Development F-score: 0.9661290749715314\n",
      "Saved model to models/spacy_ner_cntd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c1cbf1438643d4aea469a28b326399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 106312.89533996582}\n",
      "Development F-score: 0.9637986282142952\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a96cddc030347d28271d36dc6f5446a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 105938.4668750763}\n",
      "Development F-score: 0.9661555573210455\n",
      "Saved model to models/spacy_ner_cntd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff687264f75140c0a2e3661c0184eb06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 106621.87007331848}\n",
      "Development F-score: 0.9650697809909695\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469a672f8a834be89eb3f06f8f2cdd5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 106051.79179954529}\n",
      "Development F-score: 0.9655729456317365\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fb2f98196d447b988fb5719fc2bd9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: {'ner': 106155.75259017944}\n",
      "Development F-score: 0.9644342046026323\n",
      "No improvement on development set. Stop training.\n"
     ]
    }
   ],
   "source": [
    "# Training a model on top of nlp- continued training of the model\n",
    "# This model is expected to give better results as spacy's nlp is used as a base model\n",
    "output_dir_cntd = \"models/spacy_ner_cntd\"\n",
    "train(training_data, dev_data, model=nlp, output_dir=output_dir_cntd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "\t\t\tBase Model\n",
      "************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL       0.00      0.00      0.00         0\n",
      "        DATE       0.00      0.00      0.00         0\n",
      "       EVENT       0.00      0.00      0.00         0\n",
      "         FAC       0.00      0.00      0.00         0\n",
      "         GPE       0.00      0.00      0.00         0\n",
      "    LANGUAGE       0.00      0.00      0.00         0\n",
      "         LAW       0.00      0.00      0.00         0\n",
      "         LOC       0.22      0.02      0.04       823\n",
      "        MISC       0.00      0.00      0.00      1597\n",
      "       MONEY       0.00      0.00      0.00         0\n",
      "        NORP       0.00      0.00      0.00         0\n",
      "           O       0.98      0.91      0.94     63236\n",
      "     ORDINAL       0.00      0.00      0.00         0\n",
      "         ORG       0.48      0.31      0.37      1433\n",
      "         PER       0.00      0.00      0.00      1905\n",
      "     PERCENT       0.00      0.00      0.00         0\n",
      "      PERSON       0.00      0.00      0.00         0\n",
      "     PRODUCT       0.00      0.00      0.00         0\n",
      "    QUANTITY       0.00      0.00      0.00         0\n",
      "        TIME       0.00      0.00      0.00         0\n",
      " WORK_OF_ART       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.84     68994\n",
      "   macro avg       0.08      0.06      0.06     68994\n",
      "weighted avg       0.91      0.84      0.87     68994\n",
      "\n",
      "************************************************************\n",
      "\t\t\tNew Model\n",
      "************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.72      0.81      0.76       823\n",
      "        MISC       0.73      0.66      0.70      1597\n",
      "           O       0.99      1.00      1.00     63236\n",
      "         ORG       0.77      0.62      0.69      1433\n",
      "         PER       0.80      0.83      0.82      1905\n",
      "\n",
      "    accuracy                           0.98     68994\n",
      "   macro avg       0.80      0.79      0.79     68994\n",
      "weighted avg       0.97      0.98      0.97     68994\n",
      "\n",
      "************************************************************\n",
      "\t\t\tContinued Model\n",
      "************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.77      0.72      0.75       823\n",
      "        MISC       0.64      0.62      0.63      1597\n",
      "           O       0.99      1.00      1.00     63236\n",
      "         ORG       0.70      0.60      0.65      1433\n",
      "         PER       0.80      0.85      0.82      1905\n",
      "\n",
      "    accuracy                           0.97     68994\n",
      "   macro avg       0.78      0.76      0.77     68994\n",
      "weighted avg       0.97      0.97      0.97     68994\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9726063135924863, 0.9726063135924863, 0.9726063135924863, None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance Evaluation\n",
    "nlp_base = nl_core_news_sm.load()\n",
    "nlp_scratch = spacy.load(output_dir_scratch)\n",
    "nlp_cntd = spacy.load(output_dir_cntd)\n",
    "\n",
    "print(\"*\"*60)\n",
    "print(\"\\t\\t\\tBase Model\")\n",
    "print(\"*\"*60)\n",
    "evaluate(nlp_base, test_data, verbose=1)\n",
    "print(\"*\"*60)\n",
    "print(\"\\t\\t\\tNew Model\")\n",
    "print(\"*\"*60)\n",
    "evaluate(nlp_scratch, test_data, verbose=1)\n",
    "print(\"*\"*60)\n",
    "print(\"\\t\\t\\tContinued Model\")\n",
    "print(\"*\"*60)\n",
    "evaluate(nlp_cntd, test_data, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References-\n",
    "\n",
    "- https://towardsdatascience.com/custom-named-entity-recognition-using-spacy-7140ebbb3718\n",
    "- https://github.com/nlptown/nlp-notebooks/blob/master/Updating%20spaCy's%20Named%20Entity%20Recognition%20System.ipynb\n",
    "- https://spacy.io/usage/training\n",
    "- https://spacy.io/usage/linguistic-features#named-entities\n",
    "- https://spacy.io/api/goldparse\n",
    "- https://spacy.io/api/annotation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
